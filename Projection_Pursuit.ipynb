{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Projection_Pursuit.ipynb","provenance":[],"authorship_tag":"ABX9TyNbgVolKzWHv9lhYiD9weFw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rlu6FmjIVFB4","executionInfo":{"status":"ok","timestamp":1638837565235,"user_tz":480,"elapsed":8397,"user":{"displayName":"Marvin Pepito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10481302061855618161"}},"outputId":"88562536-41d0-4c34-810f-1866a0e70abd"},"source":["!pip install gudhi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gudhi\n","  Downloading gudhi-3.4.1.post1-cp37-cp37m-manylinux2014_x86_64.whl (28.2 MB)\n","\u001b[K     |████████████████████████████████| 28.2 MB 79.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.9 in /usr/local/lib/python3.7/dist-packages (from gudhi) (1.19.5)\n","Installing collected packages: gudhi\n","Successfully installed gudhi-3.4.1.post1\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pEm7GzU2VF7D","executionInfo":{"status":"ok","timestamp":1638837568770,"user_tz":480,"elapsed":3540,"user":{"displayName":"Marvin Pepito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10481302061855618161"}},"outputId":"ccbf5f02-3699-4b16-aa14-acd804f57336"},"source":["!pip install tensorflow"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.7.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.22.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n","Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (12.0.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.42.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"toL7EsSEVGIK","executionInfo":{"status":"ok","timestamp":1638837573964,"user_tz":480,"elapsed":3985,"user":{"displayName":"Marvin Pepito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10481302061855618161"}},"outputId":"912fec31-47ef-4153-fb3a-cc2ef7a51be9"},"source":["!pip install tensorflow_addons"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow_addons\n","  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 4.0 MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.15.0\n"]}]},{"cell_type":"code","metadata":{"id":"Hxkemwn-VNeJ","executionInfo":{"status":"ok","timestamp":1638837584986,"user_tz":480,"elapsed":1232,"user":{"displayName":"Marvin Pepito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10481302061855618161"}},"outputId":"87428e3a-09d1-4292-a73c-9fadb5da0cbf","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install tensorflow_manopt"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow_manopt (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for tensorflow_manopt\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"zaqa2hi2qpEW"},"source":["import numpy               as np\n","import tensorflow          as tf\n","import tensorflow_addons   as tfa\n","import matplotlib.pyplot   as plt\n","import pandas              as pd\n","import gudhi               as gd\n","\n","\n","from gudhi.wasserstein     import wasserstein_distance\n","from mpl_toolkits.mplot3d  import Axes3D\n","from sklearn.metrics       import pairwise_distances\n","\n","\n","import tensorflow_manopt as manopt\n","\n","# cylinder \n","\n","np.random.seed(1) #expand the cylinder into a rectangle and generate 300 points on it and then transform them back\n","ss3=np.random.uniform(0,2*np.pi,300)\n","noise=np.random.normal(0,0.1,300)\n","\n","noise = 0\n","xx=(1+noise)*np.cos(ss3)\n","yy=(1+noise)*np.sin(ss3)\n","#add noise if you want\n","\n","\n","rr3=np.random.uniform(0,1,300) #a point (xx,yy,rr3) on 3D\n","ax = plt.subplot(111, projection='3d')\n","ax.scatter(rr3,xx,yy) \n","plt.show()\n","\n","# 2 cylinders\n","\n","np.random.seed(1) #expand the cylinder into a rectangle and generate 300 points on it and then transform them back\n","ss3=np.random.uniform(0,2*np.pi,150)\n","noise=np.random.normal(0,0.1,150)\n","\n","noise=0\n","xx=(1+noise)*np.cos(ss3)\n","yy=(1+noise)*np.sin(ss3)\n","#add noise if you want\n","\n","\n","rr3=np.random.uniform(0,1,150) #a point (xx,yy,rr3) on 3D\n","\n","np.random.seed(100)\n","sss3=np.random.uniform(0,2*np.pi,150)\n","xxx=3+2*np.cos(sss3)\n","yyy=2*np.sin(sss3)\n","\n","xxx45=2+xxx\n","\n","\n","rrr3=np.random.uniform(0,5,150) #a point (xx,yy,rr3) on 3D\n","\n","#rotate by 45 degree\n","rrr45=rrr3*np.sqrt(2)/2-np.sqrt(2)/2*yyy\n","yyy45=rrr3*np.sqrt(2)/2+np.sqrt(2)/2*yyy\n","\n","RR=np.r_[rr3,rrr45]\n","RX=np.r_[xx,xxx]\n","RY=np.r_[yy,yyy]\n","\n","RX45=np.r_[xx,xxx45]\n","RY45=np.r_[yy,yyy45]\n","\n","ax = plt.subplot(111, projection='3d')\n","ax.scatter(RR,RX45,RY45) \n","plt.show()\n","\n","# date X\n","\n","X=np.array(np.mat([rr3,xx,yy]).T,dtype=np.float32)\n","\n","# construct persistence diagrams into tensorflow form\n","\n","def Rips(DX, mel, dim, card):\n","    # Parameters: DX (distance matrix), \n","    #             mel (maximum edge length for Rips filtration), \n","    #             dim (homological dimension), \n","    #             card (number of persistence diagram points, sorted by distance-to-diagonal)\n","\n","    # Compute the persistence pairs with Gudhi\n","    rc = gd.RipsComplex(distance_matrix=DX, max_edge_length=mel)\n","    st = rc.create_simplex_tree(max_dimension=dim+1)\n","    dgm = st.persistence()\n","    pairs = st.persistence_pairs()\n","\n","    # Retrieve vertices v_a and v_b by picking the ones achieving the maximal\n","    # distance among all pairwise distances between the simplex vertices\n","    indices, pers = [], []\n","    for s1, s2 in pairs:\n","        if len(s1) == dim+1 and len(s2) > 0:\n","            l1, l2 = np.array(s1), np.array(s2)\n","            i1 = [s1[v] for v in np.unravel_index(np.argmax(DX[l1,:][:,l1]),[len(s1), len(s1)])]\n","            i2 = [s2[v] for v in np.unravel_index(np.argmax(DX[l2,:][:,l2]),[len(s2), len(s2)])]\n","            indices += i1\n","            indices += i2\n","            pers.append(st.filtration(s2) - st.filtration(s1))\n","    \n","    # Sort points with distance-to-diagonal\n","    perm = np.argsort(pers)\n","    indices = list(np.reshape(indices, [-1,4])[perm][::-1,:].flatten())\n","    \n","    # Output indices\n","    indices = indices[:4*card] + [0 for _ in range(0,max(0,4*card-len(indices)))]\n","    return list(np.array(indices, dtype=np.int32))\n","\n","class RipsModel(tf.keras.Model):\n","    def __init__(self, P, mel=12, dim=1, card=150):\n","        super(RipsModel, self).__init__()\n","        self.P = P\n","        self.mel = mel\n","        self.dim = dim\n","        self.card = card\n","        \n","    def call(self):\n","        m, d, c = self.mel, self.dim, self.card\n","        # Compute distance matrix\n","        DX = tfa.losses.metric_learning.pairwise_distance(X)\n","        DXX = tf.reshape(DX, [1, DX.shape[0], DX.shape[1]])\n","        \n","        # Turn numpy function into tensorflow function\n","        XRipsTF = lambda DX: tf.numpy_function(Rips, [DX, m, d, c], [tf.int32 for _ in range(4*c)])\n","        \n","        # Compute vertices associated to positive and negative simplices \n","        # Don't compute gradient for this operation\n","        Xids = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(XRipsTF,DXX,dtype=[tf.int32 for _ in range(4*c)]))\n","        # Get persistence diagram by simply picking the corresponding entries in the distance matrix\n","        Xdgm = tf.reshape(tf.gather_nd(DX, tf.reshape(Xids, [2*c,2])), [c,2])\n","\n","\n","        Z=X@self.P\n","        # Compute distance matrix\n","        DZ = tfa.losses.metric_learning.pairwise_distance(Z)\n","        DZZ = tf.reshape(DZ, [1, DZ.shape[0], DZ.shape[1]])\n","        \n","        # Turn numpy function into tensorflow function\n","        ZRipsTF = lambda DZ: tf.numpy_function(Rips, [DZ, m, d, c], [tf.int32 for _ in range(4*c)])\n","        \n","        # Compute vertices associated to positive and negative simplices \n","        # Don't compute gradient for this operation\n","        Zids = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(ZRipsTF,DZZ,dtype=[tf.int32 for _ in range(4*c)]))\n","        # Get persistence diagram by simply picking the corresponding entries in the distance matrix\n","        Zdgm = tf.reshape(tf.gather_nd(DZ, tf.reshape(Zids, [2*c,2])), [c,2])\n","        return (Xdgm,Zdgm)\n","\n","# show persistence diagrams\n","\n","st = gd.RipsComplex(points = X, \n","                    max_edge_length = 100).create_simplex_tree(max_dimension=2)\n","st.persistence()\n","D = np.array(st.persistence_intervals_in_dimension(1), dtype=np.float32)\n","\n","plt.figure()\n","plt.scatter(D[:,0], D[:,1])\n","plt.plot([0,2], [0,2])\n","plt.show()\n","\n","st1 = gd.RipsComplex(points = X@np.array([[0,  0],\n","       [1 , -0 ],\n","       [ 0. , 1]]), \n","                    max_edge_length=12).create_simplex_tree(max_dimension=2)\n","#the perfect circle case\n","st1.persistence()\n","D1 = np.array(st1.persistence_intervals_in_dimension(1), dtype=np.float32)\n","\n","plt.figure()\n","plt.scatter(D1[:,0], D1[:,1])\n","plt.plot([0,2], [0,2])\n","plt.show()\n","\n","wasserstein_distance(tf.constant(D1), tf.constant(D), order=2, internal_p=2)\n","\n","data=X@np.array([[0,  0],\n","       [1 , 0 ],\n","       [ 0. , 1]])\n","x2=data[:,0].tolist()\n","y2=data[:,1].tolist()\n","fig, ax = plt.subplots()\n","ax.scatter(x2,y2)\n","plt.show()\n","\n","# Sinkhorn with lr=10 fixed\n","\n","#construct Stiefel manifold\n","S = manopt.manifolds.StiefelCanonical()\n","np.random.seed(100)\n","\n","#random P in Stiefel manifold as the initialized\n","H = np.random.rand(3, 2)\n","u, s, vh = np.linalg.svd(H, full_matrices=False)\n","P = u @ vh  #initalize P\n","'''\n","P = np.array([[-0.0984759 ,  0.07432846],\n","       [-0.5994593 , -0.8004051 ],\n","       [ 0.7943243 , -0.59483355]])\n","'''\n","\n","#convert it into tensor with float 32\n","Pinit = np.array(P, dtype=np.float32)\n","\n","P = tf.Variable(initial_value=Pinit, trainable=True)\n","\n","#assign the initialized P\n","manopt.variable.assign_to_manifold(P, S)\n","\n","#construct main model and optimization model\n","model = RipsModel(P=P, mel=12, dim=1, card = 20)\n","\n","opt = manopt.optimizers.RiemannianSGD(learning_rate= 10)\n","\n","#show the initialized transformed data\n","data=X@Pinit\n","x2=data[:,0].tolist()\n","y2=data[:,1].tolist()\n","fig, ax = plt.subplots()\n","ax.scatter(x2,y2)\n","plt.show()\n","\n","#keep track of loss and persistence diagrams after projection\n","losses, dgms = [], []\n","\n","#lr = 10, learning rate\n","for epoch in range(4+1):#learning iteration\n","    #opt = manopt.optimizers.RiemannianSGD(learning_rate = lr)\n","    #lr = 0.05*lr\n","\n","    with tf.GradientTape() as tape:#computing gradient\n","        \n","        # Compute persistence diagram\n","        Zdgm = model.call()[1]\n","        Xdgm = model.call()[0]\n","        npX = np.array(Xdgm)\n","        npZ = np.array(Zdgm)\n","        \n","        #computing Sinkhorn distance\n","        def dmat(x, y):\n","            \"\"\"\n","            :param x: (na, 2)\n","            :param y: (nb, 2)\n","            :return:\n","            \"\"\"\n","            mmp1 = tf.tile(tf.expand_dims(x, axis=1), [1, y.shape[0], 1])  # (na, nb, 2)\n","            mmp2 = tf.tile(tf.expand_dims(y, axis=0), [x.shape[0], 1, 1])  # (na, nb, 2)\n","\n","            mm = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(mmp1, mmp2)), axis=2))  # (na, nb)\n","\n","            return mm\n","        \n","        def sink(M, m_size, reg, numItermax=1000, stopThr=1e-9):\n","            # we assume that no distances are null except those of the diagonal of distances\n","            # M: extended cost matrix\n","            # reg: lambda\n","\n","            a = tf.expand_dims(tf.ones(shape=(m_size[0],)) / m_size[0], axis=1)  # (na, 1)\n","            b = tf.expand_dims(tf.ones(shape=(m_size[1],)) / m_size[1], axis=1)  # (nb, 1)\n","\n","            # init data\n","            Nini = m_size[0]\n","            Nfin = m_size[1]\n","\n","            u = tf.expand_dims(tf.ones(Nini) / Nini, axis=1)  # (na, 1)\n","            v = tf.expand_dims(tf.ones(Nfin) / Nfin, axis=1)  # (nb, 1)\n","\n","            K = tf.exp(-M / reg)  # (na, nb)\n","\n","            Kp = (1.0 / a) * K  # (na, 1) * (na, nb) = (na, nb)\n","\n","            cpt = tf.constant(0)\n","            err = tf.constant(1.0)\n","\n","            c = lambda cpt, u, v, err: tf.logical_and(cpt < numItermax, err > stopThr)\n","\n","            def err_f1():\n","                # we can speed up the process by checking for the error only all the 10th iterations\n","                transp = u * (K * tf.squeeze(v))  # (na, 1) * ((na, nb) * (nb,)) = (na, nb)\n","                err_ = tf.pow(tf.norm(tf.reduce_sum(transp) - b, ord=1), 2)  # (,)\n","                return err_\n","\n","            def err_f2():\n","                return err\n","\n","            def loop_func(cpt, u, v, err):\n","                KtransposeU = tf.matmul(tf.transpose(K, (1, 0)), u)  # (nb, na) x (na, 1) = (nb, 1)\n","                v = tf.compat.v1.div(b,KtransposeU)  # (nb, 1)\n","                u = 1.0 / tf.matmul(Kp, v)  # (na, 1)\n","\n","                err = tf.cond(tf.equal(cpt % 10, 0), err_f1, err_f2)\n","\n","                cpt = tf.add(cpt, 1)\n","                return cpt, u, v, err\n","\n","            _, u, v, _ = tf.while_loop(c, loop_func, loop_vars=[cpt, u, v, err])\n","\n","            result = tf.reduce_sum(u * K * tf.reshape(v, (1, -1)) * M)\n","\n","            return result\n","        \n","        A=np.array([[1,-1],[-1,1]])\n","        # Compute persistence diagram\n","\n","        \n","        # Loss is sum of squares of distances to the diagonal\n","        Morginal = dmat(Xdgm,Zdgm)\n","        \n","        n1,n2 = Morginal.shape\n","        Deltax=np.zeros(shape=(n1,1))\n","        Deltaz=np.zeros(shape=(1,n2+1))\n","        \n","        for i in range(n1):\n","            Deltax[i,0] = 1/2*npX[i,:]@A@npX[i,:].T\n","            \n","        for j in range(n2):\n","            Deltaz[0,j] = 1/2*npZ[j,:]@A@npZ[j,:].T\n","            \n","\n","        M=tf.square(tf.concat([tf.concat([Morginal,Deltax],1),Deltaz],0))\n","        \n","        # Sinkhorn distance as loss\n","        loss = sink(M,(n1+1,n2+1),0.05)\n","        \n","\n","    \n","    # Compute and apply gradients\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    \n","    opt.apply_gradients(zip(gradients, model.trainable_variables))\n","    \n","    #loss\n","    print(loss.numpy())\n","    \n","    #persistence diagrams after transformation\n","    losses.append(loss.numpy())\n","    Zdgmnow = model.call()[1]\n","    dgms.append(Zdgmnow)\n","    \n","    if epoch >-1:\n","        data=X@model.P.numpy()\n","        x2=data[:,0].tolist()\n","        y2=data[:,1].tolist()\n","        fig, ax = plt.subplots()\n","        ax.scatter(x2,y2)\n","        plt.show()\n","        \n","        D = Xdgm.numpy()      \n","        plt.figure()\n","        plt.scatter(D[:,0], D[:,1])\n","        \n","        \n","        for dg in dgms:\n","            plt.scatter(dg[:,0], dg[:,1], s=20, marker=\"D\", alpha=.1)\n","        plt.scatter(dgms[-1][:,0], dgms[-1][:,1], s=40, marker=\"D\", c=\"red\")\n","        plt.plot([0,2],[0,2])\n","        plt.title(\"Optimized persistence diagrams\")\n","        plt.show()\n","\n","plt.figure()\n","plt.plot(losses)\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.show()\n","\n","# Sinkhorn with lr=15 decaying 0.05 rate\n","\n","S = manopt.manifolds.StiefelCanonical()\n","np.random.seed(100)\n","\n","H = np.random.rand(3, 2)\n","u, s, vh = np.linalg.svd(H, full_matrices=False)\n","P = u @ vh  #initalize P\n","'''\n","P = np.array([[-0.0984759 ,  0.07432846],\n","       [-0.5994593 , -0.8004051 ],\n","       [ 0.7943243 , -0.59483355]])\n","'''\n","Pinit = np.array(P, dtype=np.float32)\n","\n","P = tf.Variable(initial_value=Pinit, trainable=True)\n","\n","manopt.variable.assign_to_manifold(P, S)\n","\n","model = RipsModel(P=P, mel=12, dim=1, card = 20)\n","\n","opt = manopt.optimizers.RiemannianSGD(learning_rate= 10)\n","\n","data=X@Pinit\n","x2=data[:,0].tolist()\n","y2=data[:,1].tolist()\n","fig, ax = plt.subplots()\n","ax.scatter(x2,y2)\n","plt.show()\n","\n","losses, dgms = [], []\n","lr = 15\n","for epoch in range(4+1):\n","    opt = manopt.optimizers.RiemannianSGD(learning_rate = lr)\n","    #decaying lr\n","    lr = 0.05*lr\n","\n","    with tf.GradientTape() as tape:\n","        \n","        # Compute persistence diagram\n","        Zdgm = model.call()[1]\n","        Xdgm = model.call()[0]\n","        npX = np.array(Xdgm)\n","        npZ = np.array(Zdgm)\n","                \n","        def dmat(x, y):\n","            \"\"\"\n","            :param x: (na, 2)\n","            :param y: (nb, 2)\n","            :return:\n","            \"\"\"\n","            mmp1 = tf.tile(tf.expand_dims(x, axis=1), [1, y.shape[0], 1])  # (na, nb, 2)\n","            mmp2 = tf.tile(tf.expand_dims(y, axis=0), [x.shape[0], 1, 1])  # (na, nb, 2)\n","\n","            mm = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(mmp1, mmp2)), axis=2))  # (na, nb)\n","\n","            return mm\n","        \n","        def sink(M, m_size, reg, numItermax=1000, stopThr=1e-9):\n","            # we assume that no distances are null except those of the diagonal of distances\n","\n","            a = tf.expand_dims(tf.ones(shape=(m_size[0],)) / m_size[0], axis=1)  # (na, 1)\n","            b = tf.expand_dims(tf.ones(shape=(m_size[1],)) / m_size[1], axis=1)  # (nb, 1)\n","\n","            # init data\n","            Nini = m_size[0]\n","            Nfin = m_size[1]\n","\n","            u = tf.expand_dims(tf.ones(Nini) / Nini, axis=1)  # (na, 1)\n","            v = tf.expand_dims(tf.ones(Nfin) / Nfin, axis=1)  # (nb, 1)\n","\n","            K = tf.exp(-M / reg)  # (na, nb)\n","\n","            Kp = (1.0 / a) * K  # (na, 1) * (na, nb) = (na, nb)\n","\n","            cpt = tf.constant(0)\n","            err = tf.constant(1.0)\n","\n","            c = lambda cpt, u, v, err: tf.logical_and(cpt < numItermax, err > stopThr)\n","\n","            def err_f1():\n","                # we can speed up the process by checking for the error only all the 10th iterations\n","                transp = u * (K * tf.squeeze(v))  # (na, 1) * ((na, nb) * (nb,)) = (na, nb)\n","                err_ = tf.pow(tf.norm(tf.reduce_sum(transp) - b, ord=1), 2)  # (,)\n","                return err_\n","\n","            def err_f2():\n","                return err\n","\n","            def loop_func(cpt, u, v, err):\n","                KtransposeU = tf.matmul(tf.transpose(K, (1, 0)), u)  # (nb, na) x (na, 1) = (nb, 1)\n","                v = tf.compat.v1.div(b,KtransposeU)  # (nb, 1)\n","                u = 1.0 / tf.matmul(Kp, v)  # (na, 1)\n","\n","                err = tf.cond(tf.equal(cpt % 10, 0), err_f1, err_f2)\n","\n","                cpt = tf.add(cpt, 1)\n","                return cpt, u, v, err\n","\n","            _, u, v, _ = tf.while_loop(c, loop_func, loop_vars=[cpt, u, v, err])\n","\n","            result = tf.reduce_sum(u * K * tf.reshape(v, (1, -1)) * M)\n","\n","            return result\n","        \n","        A=np.array([[1,-1],[-1,1]])\n","        # Compute persistence diagram\n","\n","        \n","        # Loss is sum of squares of distances to the diagonal\n","        Morginal = dmat(Xdgm,Zdgm)\n","        \n","        n1,n2 = Morginal.shape\n","        Deltax=np.zeros(shape=(n1,1))\n","        Deltaz=np.zeros(shape=(1,n2+1))\n","        \n","        for i in range(n1):\n","            Deltax[i,0] = 1/2*npX[i,:]@A@npX[i,:].T\n","            \n","        for j in range(n2):\n","            Deltaz[0,j] = 1/2*npZ[j,:]@A@npZ[j,:].T\n","            \n","        '''    \n","        for i in range(n1):\n","            Deltax[i,0] = (npX[i,1]-npX[i,0])**2\n","            \n","        for j in range(n2):\n","            Deltaz[0,j] = (npZ[i,1]-npZ[i,0])**2\n","        '''\n","        \n","        M=tf.square(tf.concat([tf.concat([Morginal,Deltax],1),Deltaz],0))\n","        \n","        loss = sink(M,(n1+1,n2+1),0.05)\n","        \n","        # Loss is Wasserstein distance\n","    \n","    # Compute and apply gradients\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    \n","    opt.apply_gradients(zip(gradients, model.trainable_variables))\n","    \n","    print(loss.numpy())\n","    \n","    losses.append(loss.numpy())\n","    Zdgmnow = model.call()[1]\n","    dgms.append(Zdgmnow)\n","    \n","    if epoch >-1:\n","        data=X@model.P.numpy()\n","        x2=data[:,0].tolist()\n","        y2=data[:,1].tolist()\n","        fig, ax = plt.subplots()\n","        ax.scatter(x2,y2)\n","        plt.show()\n","        \n","        D = Xdgm.numpy()      \n","        plt.figure()\n","        plt.scatter(D[:,0], D[:,1])\n","        \n","        \n","        for dg in dgms:\n","            plt.scatter(dg[:,0], dg[:,1], s=20, marker=\"D\", alpha=.1)\n","        plt.scatter(dgms[-1][:,0], dgms[-1][:,1], s=40, marker=\"D\", c=\"red\")\n","        plt.plot([0,2],[0,2])\n","        plt.title(\"Optimized persistence diagrams\")\n","        plt.show()\n","\n","plt.figure()\n","plt.plot(losses)\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.show()\n","\n","# Wasserstein with lr=10 decay rate 0.05\n","\n","S = manopt.manifolds.StiefelCanonical()\n","np.random.seed(100)\n","\n","H = np.random.rand(3, 2)\n","u, s, vh = np.linalg.svd(H, full_matrices=False)\n","P = u @ vh  #initalize P\n","'''\n","P = np.array([[-0.0984759 ,  0.07432846],\n","       [-0.5994593 , -0.8004051 ],\n","       [ 0.7943243 , -0.59483355]])\n","'''\n","Pinit = np.array(P, dtype=np.float32)\n","\n","P = tf.Variable(initial_value=Pinit, trainable=True)\n","\n","manopt.variable.assign_to_manifold(P, S)\n","\n","model = RipsModel(P=P, mel=12, dim=1, card = 150)\n","\n","'''initial_learning_rate = 0.9\n","lr = tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate,\n","    decay_steps=100000,\n","    decay_rate=0.96,\n","    staircase=False)\n","'''\n","#opt = manopt.optimizers.RiemannianSGD(learning_rate = 5)\n","\n","data=X@Pinit\n","x2=data[:,0].tolist()\n","y2=data[:,1].tolist()\n","fig, ax = plt.subplots()\n","ax.scatter(x2,y2)\n","plt.show()\n","        \n","\n","losses, dgms = [], []\n","lr = 10\n","for epoch in range(4+1):\n","    opt = manopt.optimizers.RiemannianSGD(learning_rate = lr)\n","    lr = 0.05*lr\n","\n","    with tf.GradientTape() as tape:\n","        \n","        # Compute persistence diagram\n","        Zdgm = model.call()[1]\n","        Xdgm = model.call()[0]\n","        \n","        \n","        # Loss is Wasserstein distance\n","        loss = tf.square(wasserstein_distance(Zdgm, Xdgm, order=2, internal_p=2, enable_autodiff=True))\n","    \n","    # Compute and apply gradients\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    \n","    opt.apply_gradients(zip(gradients, model.trainable_variables))\n","    \n","    print(loss.numpy())\n","    \n","    losses.append(loss.numpy())\n","    Zdgmnow = model.call()[1]\n","    dgms.append(Zdgmnow)\n","    \n","    if epoch >-1:\n","        data=X@model.P.numpy()\n","        x2=data[:,0].tolist()\n","        y2=data[:,1].tolist()\n","        fig, ax = plt.subplots()\n","        ax.scatter(x2,y2)\n","        plt.show()\n","        \n","        D = Xdgm.numpy()      \n","        plt.figure()\n","        plt.scatter(D[:,0], D[:,1])\n","        \n","        \n","        for dg in dgms:\n","            plt.scatter(dg[:,0], dg[:,1], s=20, marker=\"D\", alpha=.1)\n","        plt.scatter(dgms[-1][:,0], dgms[-1][:,1], s=40, marker=\"D\", c=\"red\")\n","        plt.plot([0,2],[0,2])\n","        plt.title(\"Optimized persistence diagrams\")\n","        plt.show()\n","\n","plt.figure()\n","plt.plot(losses)\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.show()\n","\n","# Wasserstein with lr=5 decay rate 0.05\n","\n","S = manopt.manifolds.StiefelCanonical()\n","np.random.seed(100)\n","\n","H = np.random.rand(3, 2)\n","u, s, vh = np.linalg.svd(H, full_matrices=False)\n","P = u @ vh  #initalize P\n","'''\n","P = np.array([[-0.0984759 ,  0.07432846],\n","       [-0.5994593 , -0.8004051 ],\n","       [ 0.7943243 , -0.59483355]])\n","'''\n","Pinit = np.array(P, dtype=np.float32)\n","\n","P = tf.Variable(initial_value=Pinit, trainable=True)\n","\n","manopt.variable.assign_to_manifold(P, S)\n","\n","model = RipsModel(P=P, mel=12, dim=1, card = 150)\n","\n","initial_learning_rate = 0.9\n","lr = tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate,\n","    decay_steps=100000,\n","    decay_rate=0.96,\n","    staircase=False)\n","\n","#opt = manopt.optimizers.RiemannianSGD(learning_rate = 5)\n","\n","data=X@Pinit\n","x2=data[:,0].tolist()\n","y2=data[:,1].tolist()\n","fig, ax = plt.subplots()\n","ax.scatter(x2,y2)\n","plt.show()\n","        \n","\n","#sigma=0.1\n","\n","losses, dgms = [], []\n","lr = 5\n","for epoch in range(20+1):\n","    opt = manopt.optimizers.RiemannianSGD(learning_rate = lr)\n","    lr = 0.05*lr\n","\n","    with tf.GradientTape() as tape:\n","        \n","        # Compute persistence diagram\n","        Zdgm = model.call()[1]\n","        Xdgm = model.call()[0]\n","        \n","        \n","        # Loss is Wasserstein distance\n","        loss = tf.square(wasserstein_distance(Zdgm, Xdgm, order=2, internal_p=2, enable_autodiff=True))\n","    \n","    # Compute and apply gradients\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    \n","    opt.apply_gradients(zip(gradients, model.trainable_variables))\n","    \n","    print(loss.numpy())\n","    \n","    losses.append(loss.numpy())\n","    Zdgmnow = model.call()[1]\n","    dgms.append(Zdgmnow)\n","    \n","    if epoch >-1:\n","        data=X@model.P.numpy()\n","        x2=data[:,0].tolist()\n","        y2=data[:,1].tolist()\n","        fig, ax = plt.subplots()\n","        ax.scatter(x2,y2)\n","        plt.show()\n","        \n","        D = Xdgm.numpy()      \n","        plt.figure()\n","        plt.scatter(D[:,0], D[:,1])\n","        \n","        \n","        for dg in dgms:\n","            plt.scatter(dg[:,0], dg[:,1], s=20, marker=\"D\", alpha=.1)\n","        plt.scatter(dgms[-1][:,0], dgms[-1][:,1], s=40, marker=\"D\", c=\"red\")\n","        plt.plot([0,2],[0,2])\n","        plt.title(\"Optimized persistence diagrams\")\n","        plt.show()\n","\n","plt.figure()\n","plt.plot(losses)\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.show()\n","\n","# 2 cylinders CASE 1\n","\n","S = manopt.manifolds.StiefelCanonical()\n","np.random.seed(100)\n","\n","H = np.random.rand(3, 2)\n","u, s, vh = np.linalg.svd(H, full_matrices=False)\n","P = u @ vh  #initalize P\n","'''\n","P = np.array([[-0.0984759 ,  0.07432846],\n","       [-0.5994593 , -0.8004051 ],\n","       [ 0.7943243 , -0.59483355]])\n","'''\n","Pinit = np.array(P, dtype=np.float32)\n","\n","P = tf.Variable(initial_value=Pinit, trainable=True)\n","\n","manopt.variable.assign_to_manifold(P, S)\n","\n","model = RipsModel(P=P, mel=12, dim=1, card = 150)\n","\n","initial_learning_rate = 0.9\n","lr = tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate,\n","    decay_steps=100000,\n","    decay_rate=0.96,\n","    staircase=False)\n","\n","#opt = manopt.optimizers.RiemannianSGD(learning_rate = 5)\n","\n","data=X@Pinit\n","x2=data[:,0].tolist()\n","y2=data[:,1].tolist()\n","fig, ax = plt.subplots()\n","ax.scatter(x2,y2)\n","plt.show()\n","        \n","\n","losses, dgms = [], []\n","lr = 5\n","for epoch in range(10):\n","    opt = manopt.optimizers.RiemannianSGD(learning_rate = lr)\n","    lr = 0.05*lr\n","\n","    with tf.GradientTape() as tape:\n","        \n","        # Compute persistence diagram\n","        Zdgm = model.call()[1]\n","        Xdgm = model.call()[0]\n","        \n","        \n","        # Loss is Wasserstein distance\n","        loss = tf.square(wasserstein_distance(Zdgm, Xdgm, order=2, internal_p=2, enable_autodiff=True))\n","    \n","    # Compute and apply gradients\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    \n","    opt.apply_gradients(zip(gradients, model.trainable_variables))\n","    \n","    print(loss.numpy())\n","    \n","    losses.append(loss.numpy())\n","    Zdgmnow = model.call()[1]\n","    dgms.append(Zdgmnow)\n","    \n","    if epoch >-1:\n","        data=X@model.P.numpy()\n","        x2=data[:,0].tolist()\n","        y2=data[:,1].tolist()\n","        fig, ax = plt.subplots()\n","        ax.scatter(x2,y2)\n","        plt.show()\n","        \n","        D = Xdgm.numpy()      \n","        plt.figure()\n","        plt.scatter(D[:,0], D[:,1])\n","        \n","        \n","        for dg in dgms:\n","            plt.scatter(dg[:,0], dg[:,1], s=20, marker=\"D\", alpha=.1)\n","        plt.scatter(dgms[-1][:,0], dgms[-1][:,1], s=40, marker=\"D\", c=\"red\")\n","        plt.plot([0,2],[0,2])\n","        plt.title(\"Optimized persistence diagrams\")\n","        plt.show()\n","\n","plt.figure()\n","plt.plot(losses)\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.show()\n","\n","# 2 cylinders CASE 2\n","\n","S = manopt.manifolds.StiefelCanonical()\n","np.random.seed(100)\n","\n","H = np.random.rand(3, 2)\n","u, s, vh = np.linalg.svd(H, full_matrices=False)\n","P = u @ vh  #initalize P\n","'''\n","P = np.array([[-0.0984759 ,  0.07432846],\n","       [-0.5994593 , -0.8004051 ],\n","       [ 0.7943243 , -0.59483355]])\n","'''\n","Pinit = np.array(P, dtype=np.float32)\n","\n","P = tf.Variable(initial_value=Pinit, trainable=True)\n","\n","manopt.variable.assign_to_manifold(P, S)\n","\n","model = RipsModel(P=P, mel=12, dim=1, card = 150)\n","\n","initial_learning_rate = 0.9\n","lr = tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate,\n","    decay_steps=100000,\n","    decay_rate=0.96,\n","    staircase=False)\n","\n","#opt = manopt.optimizers.RiemannianSGD(learning_rate = 5)\n","\n","data=X@Pinit\n","x2=data[:,0].tolist()\n","y2=data[:,1].tolist()\n","fig, ax = plt.subplots()\n","ax.scatter(x2,y2)\n","plt.show()\n","        \n","\n","losses, dgms = [], []\n","lr = 5\n","for epoch in range(10):\n","    opt = manopt.optimizers.RiemannianSGD(learning_rate = lr)\n","    if epoch<4:\n","        lr = 0.05*lr\n","    else:\n","        lr = lr*1.5\n","    with tf.GradientTape() as tape:\n","        \n","        # Compute persistence diagram\n","        Zdgm = model.call()[1]\n","        Xdgm = model.call()[0]\n","        \n","        \n","        # Loss is Wasserstein distance\n","        loss = tf.square(wasserstein_distance(Zdgm, Xdgm, order=2, internal_p=2, enable_autodiff=True))\n","    \n","    # Compute and apply gradients\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    \n","    opt.apply_gradients(zip(gradients, model.trainable_variables))\n","    \n","    print(loss.numpy())\n","    \n","    losses.append(loss.numpy())\n","    Zdgmnow = model.call()[1]\n","    dgms.append(Zdgmnow)\n","    \n","    if epoch >-1:\n","        data=X@model.P.numpy()\n","        x2=data[:,0].tolist()\n","        y2=data[:,1].tolist()\n","        fig, ax = plt.subplots()\n","        ax.scatter(x2,y2)\n","        plt.show()\n","        \n","        D = Xdgm.numpy()      \n","        plt.figure()\n","        plt.scatter(D[:,0], D[:,1])\n","        \n","        \n","        for dg in dgms:\n","            plt.scatter(dg[:,0], dg[:,1], s=20, marker=\"D\", alpha=.1)\n","        plt.scatter(dgms[-1][:,0], dgms[-1][:,1], s=40, marker=\"D\", c=\"red\")\n","        plt.plot([0,2],[0,2])\n","        plt.title(\"Optimized persistence diagrams\")\n","        plt.show()\n","\n","plt.figure()\n","plt.plot(losses)\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.show()"],"execution_count":null,"outputs":[]}]}